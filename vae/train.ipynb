{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.NOTSET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:data.dataset:Loaded pandas dataframe into memory\n",
      "DEBUG:data.dataset:Applying filter strategies to dataset\n",
      "DEBUG:data.dataset:Finished applying filter strategies to dataset\n",
      "DEBUG:data.dataset:Finished cleaning\n",
      "INFO:data.dataset:Created surprise dataset\n",
      "INFO:data.dataset:Finished building surprise trainset\n"
     ]
    }
   ],
   "source": [
    "from dataset import UserRatingsDataset, Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "cutoff = lambda x: 1.0 if x >= 3.5 else 0.0 # function for generating implicit ratings\n",
    "\n",
    "dataset = UserRatingsDataset(\"../data/ml-10m/ratings.csv\",threshold=20, rating_function=cutoff)\n",
    "train, valid, test = dataset.tvt_datasets()\n",
    "\n",
    "train = DataLoader(train, batch_size=100, num_workers=1)\n",
    "valid = DataLoader(valid, batch_size=100, num_workers=1)\n",
    "test = DataLoader(test, batch_size=100, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model\n",
    "model = Model(dataset.n_items, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=200,\n",
    "    log_every_n_steps=10,\n",
    "    callbacks=[EarlyStopping(monitor=\"ndcg@100\", mode=\"max\", patience=20)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | drop    | Dropout | 0     \n",
      "1 | encoder | Encoder | 6.6 M \n",
      "2 | decoder | Decoder | 6.5 M \n",
      "------------------------------------\n",
      "13.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.2 M    Total params\n",
      "52.739    Total estimated model params size (MB)\n",
      "DEBUG:fsspec.local:open file: /home/nikola/projects/deepRec/vae/lightning_logs/version_5/hparams.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikola/projects/deepRec/env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikola/projects/deepRec/env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  48%|████▊     | 271/560 [00:25<00:27, 10.44it/s, v_num=5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikola/projects/deepRec/env/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "DEBUG:fsspec.local:open file: /home/nikola/projects/deepRec/vae/lightning_logs/version_5/hparams.yaml\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
